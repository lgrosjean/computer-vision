{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_notmnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/lgrosjean/deep-learning/blob/master/1_notmnist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ojktoIKCwMtj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ]
    },
    {
      "metadata": {
        "id": "l0CV0Lz7veUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50e461ab-ce2b-480d-9187-fda069e656f2"
      },
      "cell_type": "code",
      "source": [
        "# Setup from handson-ml\n",
        "# To support both python 2 and python 3# To su \n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "    \n",
        "import imageio\n",
        "\n",
        "# Setup from udacity\n",
        "# These are all the modules we'll be using later. Make sure you can import them\n",
        "# before proceeding further.\n",
        "import sys\n",
        "import tarfile\n",
        "from IPython.display import display, Image\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from six.moves import cPickle as pickle\n",
        "\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "glNf6RHSwCsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d88217ad-0a17-4d06-bf63-13e5fdee5a16"
      },
      "cell_type": "code",
      "source": [
        "! python --version"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.3\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aEJ7aCW2wP_s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing data"
      ]
    },
    {
      "metadata": {
        "id": "R7Ew7vncvOrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://commondatastorage.googleapis.com/books1000/'\n",
        "last_percent_reported = None\n",
        "data_root = '.' # Change me to store data elsewhere\n",
        "\n",
        "def download_progress_hook(count, blockSize, totalSize):\n",
        "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
        "  slow internet connections. Reports every 5% change in download progress.\n",
        "  \"\"\"\n",
        "  global last_percent_reported\n",
        "  percent = int(count * blockSize * 100 / totalSize)\n",
        "\n",
        "  if last_percent_reported != percent:\n",
        "    if percent % 5 == 0:\n",
        "      sys.stdout.write(\"%s%%\" % percent)\n",
        "      sys.stdout.flush()\n",
        "    else:\n",
        "      sys.stdout.write(\".\")\n",
        "      sys.stdout.flush()\n",
        "      \n",
        "    last_percent_reported = percent\n",
        "        \n",
        "def maybe_download(filename, expected_bytes, force=False):\n",
        "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "  dest_filename = os.path.join(data_root, filename)\n",
        "  if force or not os.path.exists(dest_filename):\n",
        "    print('Attempting to download:', filename) \n",
        "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
        "    print('\\nDownload Complete!')\n",
        "  statinfo = os.stat(dest_filename)\n",
        "  if statinfo.st_size == expected_bytes:\n",
        "    print('Found and verified', dest_filename)\n",
        "  else:\n",
        "    raise Exception(\n",
        "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
        "  return dest_filename\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4hgdF0UZwJDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "8b9a5fdb-1d79-4011-e067-0294d37b19e5"
      },
      "cell_type": "code",
      "source": [
        "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attempting to download: notMNIST_large.tar.gz\n",
            "0%....5%....10%....15%....20%....25%....30%....35%....40%....45%....50%....55%....60%....65%....70%....75%....80%....85%....90%....95%....100%\n",
            "Download Complete!\n",
            "Found and verified ./notMNIST_large.tar.gz\n",
            "Attempting to download: notMNIST_small.tar.gz\n",
            "0%....5%....10%....15%....20%....25%....30%....35%....40%....45%....50%....55%....60%....65%....70%....75%....80%....85%....90%....95%....100%\n",
            "Download Complete!\n",
            "Found and verified ./notMNIST_small.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rRFnKKLJz5g5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Extracting data"
      ]
    },
    {
      "metadata": {
        "id": "Q48leR8awLj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8107c879-44a8-423a-db4f-43ee857fe605"
      },
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "np.random.seed(133)\n",
        "\n",
        "def maybe_extract(filename, force=False):\n",
        "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
        "  if os.path.isdir(root) and not force:\n",
        "    # You may override by setting force=True.\n",
        "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
        "  else:\n",
        "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
        "    tar = tarfile.open(filename)\n",
        "    sys.stdout.flush()\n",
        "    tar.extractall(data_root)\n",
        "    tar.close()\n",
        "  data_folders = [\n",
        "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
        "    if os.path.isdir(os.path.join(root, d))]\n",
        "  if len(data_folders) != num_classes:\n",
        "    raise Exception(\n",
        "      'Expected %d folders, one per class. Found %d instead.' % (\n",
        "        num_classes, len(data_folders)))\n",
        "  print(data_folders)\n",
        "  return data_folders\n",
        "  \n",
        "#train_folders = maybe_extract(train_filename)\n",
        "test_folders = maybe_extract(test_filename)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data for ./notMNIST_small. This may take a while. Please wait.\n",
            "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gKGRI90DyQ1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "cf803a1a-2da2-4ad9-e383-38e0392dfb9e"
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datalab',\n",
              " 'notMNIST_small.tar.gz',\n",
              " '.config',\n",
              " '.local',\n",
              " 'notMNIST_small',\n",
              " 'notMNIST_large',\n",
              " '.ipython',\n",
              " '.forever',\n",
              " '.cache',\n",
              " '.rnd',\n",
              " 'notMNIST_large.tar.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "kL4Uap4Zy9rU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d77c1231-a553-4687-f084-b7c044549ecc"
      },
      "cell_type": "code",
      "source": [
        "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attempting to download: notMNIST_large.tar.gz\n",
            "0%....5%....10%....15%....20%....25%....30%....35%....40%....45%....50%....55%....60%....65%....70%....75%....80%....85%....90%....95%....100%\n",
            "Download Complete!\n",
            "Found and verified ./notMNIST_large.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rk81_SjFyua5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9b048e21-eb13-4ef6-a13f-f112d9bb563a"
      },
      "cell_type": "code",
      "source": [
        "train_folders = maybe_extract(train_filename)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data for ./notMNIST_large. This may take a while. Please wait.\n",
            "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "phVyVAMjy5yT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "64ae264b-89ab-4b19-cfd4-a78dbf9e52cc"
      },
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\t\tnotMNIST_large.tar.gz  notMNIST_small.tar.gz\r\n",
            "notMNIST_large\tnotMNIST_small\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "reu62wSY01Hy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Problem 1"
      ]
    },
    {
      "metadata": {
        "id": "0HnYt9C10cnu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Display some images"
      ]
    },
    {
      "metadata": {
        "id": "dMDzGos00FCu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_some_images(folder, letter, number_of_images=1):\n",
        "    \"\"\"Load some pictures and print them\"\"\"\n",
        "    images_folder = os.path.join(folder, letter)\n",
        "    print(\"Folder in use : {}\".format(images_folder))\n",
        "    images = os.listdir(images_folder)\n",
        "    total_images_found = len(images)\n",
        "    print(\"{} images found !\".format(total_images_found))\n",
        "    random_list = random.sample(range(total_images_found), number_of_images)\n",
        "    print(random_list)\n",
        "    for i in random_list:\n",
        "        image_path = os.path.join(images_folder, images[i])\n",
        "        #print(image_path)\n",
        "        display(Image.open(image_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fWK145o-0Ru3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "5378fe27-26bf-4aa0-f71f-5274272b3cfc"
      },
      "cell_type": "code",
      "source": [
        "display_some_images(\"notMNIST_large\", \"C\", 2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folder in use : notMNIST_large/C\n",
            "52912 images found !\n",
            "[32701, 7621]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABo0lEQVR4nG2SPWhUURCFz8y97gZW\n0UD8QWUhFhFsVhEF7UW0MIWIRQobW7G0ElsrGxFsrBQJFi4JCgERCxHUQsGUGy20SKObRJs83p05\nFs/dd5/sqe7wMYdzLiOoFOjo9M4cn90/025bsbn+9fOH1QqpAr17g8RMzscVE1x4U5K0ZOYk6ZZK\nvgQAxcEnpJeeL9K4BCDg/DpTyf9kXI4IdulpJ0VMUFQ796zlOaODAgUQfc/9toUamWg1OTzi9tHM\nkwzYWBtu75g+shetOHcVWjPoqwfvhg7orhNXClxnI+dNAKJBBQCwTBuTxDsIsTKSEIBVet1s0EWW\nDfhdW5ZcajLNBxTNWb+Do7fg0FTKqQ5qqDw7zxCroKJRcC2r4hzOQ+oqMvf6sI+tKN5/9HHDAekc\nu2iCu7ca36cYrv0qWtPdA2EF2D1gfh7Jxq37qls3ttXrhEFplswIBPWwslBoygpICDEEAaCw+Hzh\nZ0yGyVJ0+6RNPDBARS6/TaSPTtPdUskX/3YVcvrhN2tuLsooJB07T57qze6baU+Vm3+2fnx5/+kv\n+AtLNW3ix6gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FA1E16D78D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAADN0lEQVR4nAEsA9P8AXwY7+8CEe0P\nDv4KAAT57vgI+yzqCAkd/P36BcsECvk6tg89yhaSDkokwKv0LVAQnLsaah0HDgrsCwTbRPxg/wck\nz/rXDtTS+hAEmQbYAQTQ8jyOwB1UBAkI/CMJ5u0r9NbY5/EJ9OEAAAAA+gC/UDWuGO4EDg0W2xvH\nwRTC6R8DGfobBuj0+AcUD/HxR4Qd+wT3J9Dt4hwWtREh50Qx9AcBANTRLxDTCNUeWCPrAv77Rykn\nHhs5A91ZFxX+qNa+zBqr7ysQARQbFgcEBBMHMQfSO7fMjP7KPk34ECvNIgX3LQtFA/7pAwT8AgDl\nwvuixHiD/RuGAfL5DQbeICjP7DgESezTBAIAAMx5VcRN1/k3AgT9GBnxtfICYM3R+GvzeWYEAP0A\nSFjYD0xBBAr1Gczc5dv2AP6hDQI4C/gh9wQF+QAOZzIwOh/0ysxCvIIBAj1KFg/7DicI0IDDBAzx\n4jbU9w/ves7I9+ktAAMoUDevGQUX+Q4mAvkEAOnQNusA+5enCRD3pWVw6avAnBzdBcv4IQL3CQQL\n1SAAAQAIVwETHQ9/ClFxD3RQ1AH/AAAB/yNkBPIbK+8TAO8MSx0m9hASSg1SykOpBP4A/wD/AwME\n9kUOBh8A69nfpabv9uk+dRH8rQD+AP4BKRse/gT40kL9KRrbCgcAAt0CKUMqr9H3IPFHL8UbRubg\nAg+0AAPsPgDEeZENBQIwEPwKJMJoRxJQnjMmKgECGxfYABiJHZ2P7fVGUu8a+ydc3xIVHd4VPfD9\nHQTxTSgA/hmyNikTqvbzQ/4JHs/etvR/0vsO39gCAvgcAP+ecyrGAcMKJRsJ1+vTsH3TRuJBBasI\nbesE/QQA7TMHY6HBGlfl2Mn789Yhk0LWBwD0ODb0AgB+8v7j6vnPyf/c9fPn8Ozy/v78+v////79\n//qVBPgCoibiJi3+AK8YXPQMAwD0rrtrOPro6hcaBQwC/fYR/d4aBAb2BeKfCwMA88nlHDcABvSH\nMi5M9QQS0TjTUvi4+A1O9/rbxN7X6EoniRYE9Qwf8gEMAW4UAQr2B/juAyoH8QAE6gcL8AD9/wjs\nEhH3FNMkgWgXNzbsUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FA1E16D78D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SLfskxJL09At",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load and pickle images"
      ]
    },
    {
      "metadata": {
        "id": "RaCdZVae0-i1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_size = 28  # Pixel width and height.\n",
        "pixel_depth = 255.0  # Number of levels per pixel.\n",
        "\n",
        "def load_letter(folder, min_num_images):\n",
        "  \"\"\"Load the data for a single letter label.\"\"\"\n",
        "  image_files = os.listdir(folder)\n",
        "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
        "                         dtype=np.float32)\n",
        "  print(folder)\n",
        "  num_images = 0\n",
        "  for image in image_files:\n",
        "    image_file = os.path.join(folder, image)\n",
        "    try:\n",
        "      image_data = (imageio.imread(image_file).astype(float) - \n",
        "                    pixel_depth / 2) / pixel_depth\n",
        "      if image_data.shape != (image_size, image_size):\n",
        "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
        "      dataset[num_images, :, :] = image_data\n",
        "      num_images = num_images + 1\n",
        "    except (IOError, ValueError) as e:\n",
        "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
        "    \n",
        "  dataset = dataset[0:num_images, :, :]\n",
        "  if num_images < min_num_images:\n",
        "    raise Exception('Many fewer images than expected: %d < %d' %\n",
        "                    (num_images, min_num_images))\n",
        "    \n",
        "  print('Full dataset tensor:', dataset.shape)\n",
        "  print('Mean:', np.mean(dataset))\n",
        "  print('Standard deviation:', np.std(dataset))\n",
        "  return dataset\n",
        "        \n",
        "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
        "  dataset_names = []\n",
        "  for folder in data_folders:\n",
        "    set_filename = folder + '.pickle'\n",
        "    dataset_names.append(set_filename)\n",
        "    if os.path.exists(set_filename) and not force:\n",
        "      # You may override by setting force=True.\n",
        "      print('%s already present - Skipping pickling.' % set_filename)\n",
        "    else:\n",
        "      print('Pickling %s.' % set_filename)\n",
        "      dataset = load_letter(folder, min_num_images_per_class)\n",
        "      try:\n",
        "        with open(set_filename, 'wb') as f:\n",
        "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
        "      except Exception as e:\n",
        "        print('Unable to save data to', set_filename, ':', e)\n",
        "  \n",
        "  return dataset_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Ahh8OJh1DdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "fdf43fd1-c21a-4b2a-8aeb-22cdee81f593"
      },
      "cell_type": "code",
      "source": [
        "test_datasets = maybe_pickle(test_folders, 1800)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pickling ./notMNIST_small/A.pickle.\n",
            "./notMNIST_small/A\n",
            "Could not read: ./notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
            "Full dataset tensor: (1872, 28, 28)\n",
            "Mean: -0.13262638\n",
            "Standard deviation: 0.44512787\n",
            "Pickling ./notMNIST_small/B.pickle.\n",
            "./notMNIST_small/B\n",
            "Full dataset tensor: (1873, 28, 28)\n",
            "Mean: 0.0053560836\n",
            "Standard deviation: 0.45711526\n",
            "Pickling ./notMNIST_small/C.pickle.\n",
            "./notMNIST_small/C\n",
            "Full dataset tensor: (1873, 28, 28)\n",
            "Mean: -0.14152053\n",
            "Standard deviation: 0.44269028\n",
            "Pickling ./notMNIST_small/D.pickle.\n",
            "./notMNIST_small/D\n",
            "Full dataset tensor: (1873, 28, 28)\n",
            "Mean: -0.04921665\n",
            "Standard deviation: 0.459759\n",
            "Pickling ./notMNIST_small/E.pickle.\n",
            "./notMNIST_small/E\n",
            "Full dataset tensor: (1873, 28, 28)\n",
            "Mean: -0.05991477\n",
            "Standard deviation: 0.45734972\n",
            "Pickling ./notMNIST_small/F.pickle.\n",
            "./notMNIST_small/F\n",
            "Could not read: ./notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
            "Full dataset tensor: (1872, 28, 28)\n",
            "Mean: -0.11818534\n",
            "Standard deviation: 0.45227864\n",
            "Pickling ./notMNIST_small/G.pickle.\n",
            "./notMNIST_small/G\n",
            "Full dataset tensor: (1872, 28, 28)\n",
            "Mean: -0.09255034\n",
            "Standard deviation: 0.4490059\n",
            "Pickling ./notMNIST_small/H.pickle.\n",
            "./notMNIST_small/H\n",
            "Full dataset tensor: (1872, 28, 28)\n",
            "Mean: -0.05868925\n",
            "Standard deviation: 0.45875895\n",
            "Pickling ./notMNIST_small/I.pickle.\n",
            "./notMNIST_small/I\n",
            "Full dataset tensor: (1872, 28, 28)\n",
            "Mean: 0.052645065\n",
            "Standard deviation: 0.4718935\n",
            "Pickling ./notMNIST_small/J.pickle.\n",
            "./notMNIST_small/J\n",
            "Full dataset tensor: (1872, 28, 28)\n",
            "Mean: -0.15168922\n",
            "Standard deviation: 0.44801357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_O_W8mr11GAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "outputId": "223ee5d7-785f-4c46-c01a-dca7dc1f74c8"
      },
      "cell_type": "code",
      "source": [
        "train_datasets = maybe_pickle(train_folders, 45000)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pickling ./notMNIST_large/A.pickle.\n",
            "./notMNIST_large/A\n",
            "Could not read: ./notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
            "Could not read: ./notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
            "Could not read: ./notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
            "Full dataset tensor: (52909, 28, 28)\n",
            "Mean: -0.12825017\n",
            "Standard deviation: 0.44312042\n",
            "Pickling ./notMNIST_large/B.pickle.\n",
            "./notMNIST_large/B\n",
            "Could not read: ./notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
            "Full dataset tensor: (52911, 28, 28)\n",
            "Mean: -0.0075630588\n",
            "Standard deviation: 0.45449132\n",
            "Pickling ./notMNIST_large/C.pickle.\n",
            "./notMNIST_large/C\n",
            "Full dataset tensor: (52912, 28, 28)\n",
            "Mean: -0.14225817\n",
            "Standard deviation: 0.43980625\n",
            "Pickling ./notMNIST_large/D.pickle.\n",
            "./notMNIST_large/D\n",
            "Could not read: ./notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
            "Full dataset tensor: (52911, 28, 28)\n",
            "Mean: -0.057367668\n",
            "Standard deviation: 0.45564738\n",
            "Pickling ./notMNIST_large/E.pickle.\n",
            "./notMNIST_large/E\n",
            "Full dataset tensor: (52912, 28, 28)\n",
            "Mean: -0.069898926\n",
            "Standard deviation: 0.45294192\n",
            "Pickling ./notMNIST_large/F.pickle.\n",
            "./notMNIST_large/F\n",
            "Full dataset tensor: (52912, 28, 28)\n",
            "Mean: -0.1255834\n",
            "Standard deviation: 0.4470894\n",
            "Pickling ./notMNIST_large/G.pickle.\n",
            "./notMNIST_large/G\n",
            "Full dataset tensor: (52912, 28, 28)\n",
            "Mean: -0.09458168\n",
            "Standard deviation: 0.44623995\n",
            "Pickling ./notMNIST_large/H.pickle.\n",
            "./notMNIST_large/H\n",
            "Full dataset tensor: (52912, 28, 28)\n",
            "Mean: -0.06852209\n",
            "Standard deviation: 0.45423156\n",
            "Pickling ./notMNIST_large/I.pickle.\n",
            "./notMNIST_large/I\n",
            "Full dataset tensor: (52912, 28, 28)\n",
            "Mean: 0.030786265\n",
            "Standard deviation: 0.46889856\n",
            "Pickling ./notMNIST_large/J.pickle.\n",
            "./notMNIST_large/J\n",
            "Full dataset tensor: (52911, 28, 28)\n",
            "Mean: -0.15335843\n",
            "Standard deviation: 0.44365615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "geOApF8G35Cd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test and display an image from pickle file"
      ]
    },
    {
      "metadata": {
        "id": "Mz92q3Jo1J_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f23837f-6417-47c2-9cb1-564140968cb7"
      },
      "cell_type": "code",
      "source": [
        "type(train_datasets)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "9UfhhDAC2P2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b2901d7-7422-4707-c706-27d68f5d112e"
      },
      "cell_type": "code",
      "source": [
        "train_datasets[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./notMNIST_large/A.pickle'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "3IMZeyRX2R99",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig = pickle.load(open(train_datasets[0], 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YShNuwKr25KT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8d2646b-6a86-44f3-f038-5060f75a1e72"
      },
      "cell_type": "code",
      "source": [
        "fig[0].shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "pGbIJRzD3AVG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = fig.ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CXyV2uNA39fo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Problem 2"
      ]
    },
    {
      "metadata": {
        "id": "O0_q4o1h4Blz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train, val, test files"
      ]
    },
    {
      "metadata": {
        "id": "-X-LrpBj3-6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_arrays(nb_rows, img_size):\n",
        "  if nb_rows:\n",
        "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
        "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
        "  else:\n",
        "    dataset, labels = None, None\n",
        "  return dataset, labels\n",
        "\n",
        "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
        "  num_classes = len(pickle_files)\n",
        "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
        "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
        "  vsize_per_class = valid_size // num_classes\n",
        "  tsize_per_class = train_size // num_classes\n",
        "    \n",
        "  start_v, start_t = 0, 0\n",
        "  end_v, end_t = vsize_per_class, tsize_per_class\n",
        "  end_l = vsize_per_class+tsize_per_class\n",
        "  for label, pickle_file in enumerate(pickle_files):       \n",
        "    try:\n",
        "      with open(pickle_file, 'rb') as f:\n",
        "        letter_set = pickle.load(f)\n",
        "        # let's shuffle the letters to have random validation and training set\n",
        "        np.random.shuffle(letter_set)\n",
        "        if valid_dataset is not None:\n",
        "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
        "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
        "          valid_labels[start_v:end_v] = label\n",
        "          start_v += vsize_per_class\n",
        "          end_v += vsize_per_class\n",
        "                    \n",
        "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
        "        train_dataset[start_t:end_t, :, :] = train_letter\n",
        "        train_labels[start_t:end_t] = label\n",
        "        start_t += tsize_per_class\n",
        "        end_t += tsize_per_class\n",
        "    except Exception as e:\n",
        "      print('Unable to process data from', pickle_file, ':', e)\n",
        "      raise\n",
        "    \n",
        "  return valid_dataset, valid_labels, train_dataset, train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0g8vTxYf4Frn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_size = 200000\n",
        "valid_size = 10000\n",
        "test_size = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTv7VbL74LCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "49cc5bf0-8ff9-4e02-8a47-e6fe287f7c6b"
      },
      "cell_type": "code",
      "source": [
        "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
        "  train_datasets, train_size, valid_size)\n",
        "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
        "\n",
        "print('Training:', train_dataset.shape, train_labels.shape)\n",
        "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
        "print('Testing:', test_dataset.shape, test_labels.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (200000, 28, 28) (200000,)\n",
            "Validation: (10000, 28, 28) (10000,)\n",
            "Testing: (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xmdqVuGw4Qff",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Randomize the data"
      ]
    },
    {
      "metadata": {
        "id": "_-i3lhnb4M7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def randomize(dataset, labels):\n",
        "  permutation = np.random.permutation(labels.shape[0])\n",
        "  shuffled_dataset = dataset[permutation,:,:]\n",
        "  shuffled_labels = labels[permutation]\n",
        "  return shuffled_dataset, shuffled_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sktphxVp4W6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
        "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
        "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I6l1C1Vu4XwK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SjE_zHTq4aBw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Saving the data for future uses"
      ]
    },
    {
      "metadata": {
        "id": "Turqwhtw4bqK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
        "\n",
        "try:\n",
        "  f = open(pickle_file, 'wb')\n",
        "  save = {\n",
        "    'train_dataset': train_dataset,\n",
        "    'train_labels': train_labels,\n",
        "    'valid_dataset': valid_dataset,\n",
        "    'valid_labels': valid_labels,\n",
        "    'test_dataset': test_dataset,\n",
        "    'test_labels': test_labels,\n",
        "    }\n",
        "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
        "  f.close()\n",
        "except Exception as e:\n",
        "  print('Unable to save data to', pickle_file, ':', e)\n",
        "  raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6StjaQ6x4fkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c4815ba-a9a5-419f-8643-c606e05eead2"
      },
      "cell_type": "code",
      "source": [
        "statinfo = os.stat(pickle_file)\n",
        "print('Compressed pickle size:', statinfo.st_size)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compressed pickle size: 690800506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lFqorq2G4jBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
